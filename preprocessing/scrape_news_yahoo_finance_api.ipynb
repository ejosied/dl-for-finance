{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decb70c1",
   "metadata": {},
   "source": [
    "# Scrape Text from Yahoo Finance News\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e1ab0",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa692f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557d4e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated 2022-12-19\n"
     ]
    }
   ],
   "source": [
    "date_today = datetime.now().date()\n",
    "print(f'Last updated {date_today}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393cdc30",
   "metadata": {},
   "source": [
    "## Scrape news from yfinance library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9ba74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = ['MSFT', 'AAPL', 'GOOG', 'META', 'TSLA', 'SPY', 'NVDA', 'AMZN', 'COMP', 'FANG', '^GSPC',\n",
    "           'CSCO', 'WFC', 'C', 'JPM', 'BCS', 'MS', 'CS', 'HPQ', 'BAC', 'CRM', 'NKE', 'DOW', 'VOO', '^IXIC', 'DELL', 'INTC', 'ADBE', 'PYPL', 'IBM', 'GS', 'AXP', 'MA', 'V', 'ORCL',\n",
    "           'LLY', 'SPOT', 'UA', 'NFLX', 'WRBY', 'TGT', 'WMT', 'FORD', 'DUOL', 'TM', 'HD', 'CVS', 'ZM', 'DIS', 'ADDYY', 'ARHS', 'GE', 'GM', 'PTON', 'LOW', 'JNJ', 'WBD', 'SHOP', 'PINS', 'RTX', 'BIRD', 'LULU', 'BA', 'PFE', 'PG', 'SBUX', 'COST',\n",
    "           'CVX', 'ACI', 'SFM', 'AJRD', 'LMT', 'HBAN', 'SONY', 'HON', 'COF', 'MRNA', 'CRWD', 'FDX', 'RLLCF', 'CFG', 'VZ', 'KTOS', 'XOM', 'GD', 'VWAGY', 'MZDAY', 'APH', 'KR', 'COSM', 'FWONA', 'UPS', 'MDB', 'NTDOY', 'HMC', 'MAXR', 'CAT', 'SYF', 'KO', 'AZN', 'T', 'SHEL', 'FUJHY', 'NTIC', 'DNUT', 'PEP', 'CMG', 'NSANY', 'WMG', 'FOX', 'TTE', 'CMCSA', 'PNC', 'TMUS', 'NVAX', 'NOC', 'BP', 'BNTX', 'NVS', 'EA', 'TXT', 'FITB',\n",
    "           'AMD', 'CZNC', 'XPEV', 'NKLA', 'BYDDY', 'LUMN', 'BSRR', 'CSWI', 'AGCO', 'FBIZ', 'LNN', 'CCBG', 'LI', 'EBTC', 'CFFI', 'DE', 'FELE', 'MBWM', 'NIO', 'RIVN', 'FNLC', 'EQBK',\n",
    "           'RS', 'W', 'TAL', 'X', 'GOTU', 'DAL', 'UAL', 'SXC', 'AAL', 'LUV', 'ZEUS', 'CMC', 'TMST', 'JBLU', 'ALK', 'EXAS', 'SAVE', 'WFRD', 'SCHN', 'BKR']     # specify indices of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb00620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to scrape body text, headlines, and puslish date from approved URLs\n",
    "def scrape_news(url, columns=['news', 'headlines', 'raw_publish_date', 'publish_date'], verbose=0):\n",
    "    if verbose > 0:\n",
    "        print(url)\n",
    "        \n",
    "    # send request\n",
    "    response = requests.get(url)\n",
    "    if verbose > 0:\n",
    "        print(response.status_code, response.reason, '\\n')\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return\n",
    "   \n",
    "    # valid response; proceed\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    \n",
    "    text = soup.find('div', attrs={'class': 'caas-body'}).text.replace('\\xa0', ' ')     # obtain body text\n",
    "    headlines = soup.find_all('h1')     # obtain headlines and titles\n",
    "    for n, head in enumerate(headlines):\n",
    "        headlines[n] = head.text\n",
    "    raw_publish_date = soup.find('time').text     # obtain time of publish\n",
    "    try:\n",
    "        publish_date = datetime.strptime(raw_publish_date, '%B %d, %Y, %I:%M %p')     # obtain processed datetime\n",
    "    except:\n",
    "        publish_date = None\n",
    "            \n",
    "    return dict(zip(columns, [text, headlines, raw_publish_date, publish_date]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2cd4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading MSFT -- 8 urls\n",
      "loading AAPL -- 8 urls\n",
      "loading GOOG -- 8 urls\n",
      "loading META -- 8 urls\n",
      "loading TSLA -- 8 urls\n",
      "loading SPY -- 8 urls\n",
      "loading NVDA -- 8 urls\n",
      "loading AMZN -- 8 urls\n",
      "loading COMP -- 8 urls\n",
      "loading FANG -- 8 urls\n",
      "loading ^GSPC -- 8 urls\n",
      "loading CSCO -- 8 urls\n",
      "loading WFC -- 8 urls\n",
      "loading C -- 8 urls\n",
      "loading JPM -- 8 urls\n",
      "loading BCS -- 8 urls\n",
      "loading MS -- 8 urls\n",
      "loading CS -- 8 urls\n",
      "loading HPQ -- 8 urls\n",
      "loading BAC -- 8 urls\n",
      "loading CRM -- 8 urls\n",
      "loading NKE -- 8 urls\n",
      "loading DOW -- 8 urls\n",
      "loading VOO -- 3 urls\n",
      "loading ^IXIC -- 8 urls\n",
      "loading DELL -- 8 urls\n",
      "loading INTC -- 8 urls\n",
      "loading ADBE -- 8 urls\n",
      "loading PYPL -- 8 urls\n",
      "loading IBM -- 8 urls\n",
      "loading GS -- 8 urls\n",
      "loading AXP -- 8 urls\n",
      "loading MA -- 8 urls\n",
      "loading V -- 8 urls\n",
      "loading ORCL -- 8 urls\n",
      "loading LLY -- 8 urls\n",
      "loading SPOT -- 8 urls\n",
      "loading UA -- 8 urls\n",
      "loading NFLX -- 8 urls\n",
      "loading WRBY -- 8 urls\n",
      "loading TGT -- 8 urls\n",
      "loading WMT -- 8 urls\n",
      "loading FORD -- 2 urls\n",
      "loading DUOL -- 8 urls\n",
      "loading TM -- 8 urls\n",
      "loading HD -- 8 urls\n",
      "loading CVS -- 8 urls\n",
      "loading ZM -- 8 urls\n",
      "loading DIS -- 8 urls\n",
      "loading ADDYY -- 8 urls\n",
      "loading ARHS -- 8 urls\n",
      "loading GE -- 8 urls\n",
      "loading GM -- 8 urls\n",
      "loading PTON -- 8 urls\n",
      "loading LOW -- 8 urls\n",
      "loading JNJ -- 8 urls\n",
      "loading WBD -- 8 urls\n",
      "loading SHOP -- 8 urls\n",
      "loading PINS -- 8 urls\n",
      "loading RTX -- 8 urls\n",
      "loading BIRD -- 8 urls\n",
      "loading LULU -- 8 urls\n",
      "loading BA -- 8 urls\n",
      "loading PFE -- 8 urls\n",
      "loading PG -- 8 urls\n",
      "loading SBUX -- 8 urls\n",
      "loading COST -- 8 urls\n",
      "loading CVX -- 8 urls\n",
      "loading ACI -- 8 urls\n",
      "loading SFM -- 8 urls\n",
      "loading AJRD -- 8 urls\n",
      "loading LMT -- 8 urls\n",
      "loading HBAN -- 8 urls\n",
      "loading SONY -- 8 urls\n",
      "loading HON -- 8 urls\n",
      "loading COF -- 8 urls\n",
      "loading MRNA -- 8 urls\n",
      "loading CRWD -- 8 urls\n",
      "loading FDX -- 8 urls\n",
      "loading RLLCF -- 8 urls\n",
      "loading CFG -- 8 urls\n",
      "loading VZ -- 8 urls\n",
      "loading KTOS -- 8 urls\n",
      "loading XOM -- 8 urls\n",
      "loading GD -- 8 urls\n",
      "loading VWAGY -- 8 urls\n",
      "loading MZDAY -- 8 urls\n",
      "loading APH -- 8 urls\n",
      "loading KR -- 8 urls\n",
      "loading COSM -- 8 urls\n",
      "loading FWONA -- 8 urls\n",
      "loading UPS -- 8 urls\n",
      "loading MDB -- 8 urls\n",
      "loading NTDOY -- 8 urls\n",
      "loading HMC -- 8 urls\n",
      "loading MAXR -- 8 urls\n",
      "loading CAT -- 8 urls\n",
      "loading SYF -- 8 urls\n",
      "loading KO -- 8 urls\n",
      "loading AZN -- 8 urls\n",
      "loading T -- 8 urls\n",
      "loading SHEL -- 8 urls\n",
      "loading FUJHY -- 8 urls\n",
      "loading NTIC -- 8 urls\n",
      "loading DNUT -- 8 urls\n",
      "loading PEP -- 8 urls\n",
      "loading CMG -- 8 urls\n",
      "loading NSANY -- 8 urls\n",
      "loading WMG -- 8 urls\n",
      "loading FOX -- 8 urls\n",
      "loading TTE -- 8 urls\n",
      "loading CMCSA -- 8 urls\n",
      "loading PNC -- 8 urls\n",
      "loading TMUS -- 8 urls\n",
      "loading NVAX -- 8 urls\n",
      "loading NOC -- 8 urls\n",
      "loading BP -- 8 urls\n",
      "loading BNTX -- 8 urls\n",
      "loading NVS -- 8 urls\n",
      "loading EA -- 8 urls\n",
      "loading TXT -- 8 urls\n",
      "loading FITB -- 8 urls\n",
      "loading AMD -- 8 urls\n",
      "loading CZNC -- 2 urls\n",
      "loading XPEV -- 8 urls\n",
      "loading NKLA -- 8 urls\n",
      "loading BYDDY -- 8 urls\n",
      "loading LUMN -- 8 urls\n",
      "loading BSRR -- 8 urls\n",
      "loading CSWI -- 8 urls\n",
      "loading AGCO -- 8 urls\n",
      "loading FBIZ -- 8 urls\n",
      "loading LNN -- 8 urls\n",
      "loading CCBG -- 8 urls\n",
      "loading LI -- 8 urls\n",
      "loading EBTC -- 7 urls\n",
      "loading CFFI -- 3 urls\n",
      "loading DE -- 8 urls\n",
      "loading FELE -- 8 urls\n",
      "loading MBWM -- 8 urls\n",
      "loading NIO -- 8 urls\n",
      "loading RIVN -- 8 urls\n",
      "loading FNLC -- 6 urls\n",
      "loading EQBK -- 8 urls\n",
      "loading RS -- 8 urls\n",
      "loading W -- 8 urls\n",
      "loading TAL -- 8 urls\n",
      "loading X -- 8 urls\n",
      "loading GOTU -- 3 urls\n",
      "loading DAL -- 8 urls\n",
      "loading UAL -- 8 urls\n",
      "loading SXC -- 8 urls\n",
      "loading AAL -- 8 urls\n",
      "loading LUV -- 8 urls\n",
      "loading ZEUS -- 8 urls\n",
      "loading CMC -- 8 urls\n",
      "loading TMST -- 8 urls\n",
      "loading JBLU -- 8 urls\n",
      "loading ALK -- 8 urls\n",
      "loading EXAS -- 8 urls\n",
      "loading SAVE -- 8 urls\n",
      "loading WFRD -- 8 urls\n",
      "loading SCHN -- 8 urls\n",
      "loading BKR -- 8 urls\n"
     ]
    }
   ],
   "source": [
    "verbose = 0\n",
    "scrape_dict = []\n",
    "\n",
    "for index in indices:\n",
    "    print(f'loading {index}', end=' -- ')\n",
    "\n",
    "    # obtain news\n",
    "    try:\n",
    "        news = yf.Ticker(index).news\n",
    "        print(f'{len(news)} urls')\n",
    "        \n",
    "    except:\n",
    "        print('no news')\n",
    "        continue\n",
    "        \n",
    "    for num, d in enumerate(news):\n",
    "\n",
    "        if verbose > 1:\n",
    "            print(f'\\t{num}  |  {d[\"title\"]}',)\n",
    "            print(f'\\t{d[\"link\"]}')\n",
    "            print(f'\\t{\" \".join(d[\"relatedTickers\"])}\\n')\n",
    "\n",
    "        link = news[num]['link']\n",
    "        scrape_results = scrape_news(url=link, verbose=verbose)\n",
    "        if scrape_results is not None:\n",
    "            scrape_results['scrape_date'] = date_today\n",
    "            scrape_results['index'] = index\n",
    "            scrape_results['url'] = link\n",
    "            scrape_results['related_tickers'] = d['relatedTickers']\n",
    "            scrape_dict.append(scrape_results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447d546f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>index</th>\n",
       "      <th>url</th>\n",
       "      <th>news</th>\n",
       "      <th>headlines</th>\n",
       "      <th>raw_publish_date</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>related_tickers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>https://finance.yahoo.com/news/paid-hack-nouri...</td>\n",
       "      <td>'A paid hack': Nouriel Roubini called out Kevi...</td>\n",
       "      <td>[Yahoo Finance, 'A paid hack': Nouriel Roubini...</td>\n",
       "      <td>December 19, 2022, 7:05 AM</td>\n",
       "      <td>2022-12-19 07:05:00</td>\n",
       "      <td>[JNJ, MSFT, HD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>https://finance.yahoo.com/news/cisco-csco-join...</td>\n",
       "      <td>Cisco Systems CSCO recently announced its part...</td>\n",
       "      <td>[Yahoo Finance, Cisco (CSCO) Joins Forces With...</td>\n",
       "      <td>December 19, 2022, 6:19 AM</td>\n",
       "      <td>2022-12-19 06:19:00</td>\n",
       "      <td>[CSCO, WIT, MSFT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>https://finance.yahoo.com/news/12-most-advance...</td>\n",
       "      <td>In this article, we discuss the 12 most advanc...</td>\n",
       "      <td>[Yahoo Finance, 12 Most Advanced Countries in ...</td>\n",
       "      <td>December 19, 2022, 6:01 AM</td>\n",
       "      <td>2022-12-19 06:01:00</td>\n",
       "      <td>[TTC, LNN, MSFT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>https://finance.yahoo.com/news/microsoft-corpo...</td>\n",
       "      <td>Microsoft (MSFT) has recently been on Zacks.co...</td>\n",
       "      <td>[Yahoo Finance, Microsoft Corporation (MSFT) i...</td>\n",
       "      <td>December 19, 2022, 6:00 AM</td>\n",
       "      <td>2022-12-19 06:00:00</td>\n",
       "      <td>[MSFT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>https://finance.yahoo.com/news/investors-heavi...</td>\n",
       "      <td>Apple (AAPL) has recently been on Zacks.com's ...</td>\n",
       "      <td>[Yahoo Finance, Investors Heavily Search Apple...</td>\n",
       "      <td>December 19, 2022, 6:00 AM</td>\n",
       "      <td>2022-12-19 06:00:00</td>\n",
       "      <td>[AAPL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>BKR</td>\n",
       "      <td>https://finance.yahoo.com/news/permian-oil-dri...</td>\n",
       "      <td>In its weekly release, Baker Hughes Company BK...</td>\n",
       "      <td>[Yahoo Finance, Permian Oil Drilling Rig Count...</td>\n",
       "      <td>December 19, 2022, 5:13 AM</td>\n",
       "      <td>2022-12-19 05:13:00</td>\n",
       "      <td>[EOG, BKR, DVN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>BKR</td>\n",
       "      <td>https://finance.yahoo.com/news/baker-hughes-re...</td>\n",
       "      <td>HOUSTON, TX and LONDON, ENGLAND / ACCESSWIRE /...</td>\n",
       "      <td>[Yahoo Finance, Baker Hughes Recognized by For...</td>\n",
       "      <td>December 14, 2022, 5:10 AM</td>\n",
       "      <td>2022-12-14 05:10:00</td>\n",
       "      <td>[BKR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>BKR</td>\n",
       "      <td>https://finance.yahoo.com/news/baker-hughes-ad...</td>\n",
       "      <td>Baker HughesThe Nasdaq-100 is one of the world...</td>\n",
       "      <td>[Yahoo Finance, Baker Hughes Added to the Nasd...</td>\n",
       "      <td>December 12, 2022, 5:00 AM</td>\n",
       "      <td>2022-12-12 05:00:00</td>\n",
       "      <td>[BKR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>BKR</td>\n",
       "      <td>https://finance.yahoo.com/news/annual-changes-...</td>\n",
       "      <td>Nasdaq, Inc.NEW YORK, Dec. 09, 2022 (GLOBE NEW...</td>\n",
       "      <td>[Yahoo Finance, Annual Changes to the Nasdaq-1...</td>\n",
       "      <td>December 9, 2022, 5:00 PM</td>\n",
       "      <td>2022-12-09 17:00:00</td>\n",
       "      <td>[CSGP, WBD, BAIDF, BIDU, GFS, SWKS, FANG, ^NDX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>BKR</td>\n",
       "      <td>https://finance.yahoo.com/news/baker-hughes-la...</td>\n",
       "      <td>Wells2Watts consortium is a private industrial...</td>\n",
       "      <td>[Yahoo Finance, Baker Hughes Launches Consorti...</td>\n",
       "      <td>December 8, 2022, 7:15 AM</td>\n",
       "      <td>2022-12-08 07:15:00</td>\n",
       "      <td>[BKR]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>693 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    scrape_date index                                                url  \\\n",
       "0    2022-12-19  MSFT  https://finance.yahoo.com/news/paid-hack-nouri...   \n",
       "1    2022-12-19  MSFT  https://finance.yahoo.com/news/cisco-csco-join...   \n",
       "2    2022-12-19  MSFT  https://finance.yahoo.com/news/12-most-advance...   \n",
       "3    2022-12-19  MSFT  https://finance.yahoo.com/news/microsoft-corpo...   \n",
       "4    2022-12-19  AAPL  https://finance.yahoo.com/news/investors-heavi...   \n",
       "..          ...   ...                                                ...   \n",
       "688  2022-12-19   BKR  https://finance.yahoo.com/news/permian-oil-dri...   \n",
       "689  2022-12-19   BKR  https://finance.yahoo.com/news/baker-hughes-re...   \n",
       "690  2022-12-19   BKR  https://finance.yahoo.com/news/baker-hughes-ad...   \n",
       "691  2022-12-19   BKR  https://finance.yahoo.com/news/annual-changes-...   \n",
       "692  2022-12-19   BKR  https://finance.yahoo.com/news/baker-hughes-la...   \n",
       "\n",
       "                                                  news  \\\n",
       "0    'A paid hack': Nouriel Roubini called out Kevi...   \n",
       "1    Cisco Systems CSCO recently announced its part...   \n",
       "2    In this article, we discuss the 12 most advanc...   \n",
       "3    Microsoft (MSFT) has recently been on Zacks.co...   \n",
       "4    Apple (AAPL) has recently been on Zacks.com's ...   \n",
       "..                                                 ...   \n",
       "688  In its weekly release, Baker Hughes Company BK...   \n",
       "689  HOUSTON, TX and LONDON, ENGLAND / ACCESSWIRE /...   \n",
       "690  Baker HughesThe Nasdaq-100 is one of the world...   \n",
       "691  Nasdaq, Inc.NEW YORK, Dec. 09, 2022 (GLOBE NEW...   \n",
       "692  Wells2Watts consortium is a private industrial...   \n",
       "\n",
       "                                             headlines  \\\n",
       "0    [Yahoo Finance, 'A paid hack': Nouriel Roubini...   \n",
       "1    [Yahoo Finance, Cisco (CSCO) Joins Forces With...   \n",
       "2    [Yahoo Finance, 12 Most Advanced Countries in ...   \n",
       "3    [Yahoo Finance, Microsoft Corporation (MSFT) i...   \n",
       "4    [Yahoo Finance, Investors Heavily Search Apple...   \n",
       "..                                                 ...   \n",
       "688  [Yahoo Finance, Permian Oil Drilling Rig Count...   \n",
       "689  [Yahoo Finance, Baker Hughes Recognized by For...   \n",
       "690  [Yahoo Finance, Baker Hughes Added to the Nasd...   \n",
       "691  [Yahoo Finance, Annual Changes to the Nasdaq-1...   \n",
       "692  [Yahoo Finance, Baker Hughes Launches Consorti...   \n",
       "\n",
       "               raw_publish_date        publish_date  \\\n",
       "0    December 19, 2022, 7:05 AM 2022-12-19 07:05:00   \n",
       "1    December 19, 2022, 6:19 AM 2022-12-19 06:19:00   \n",
       "2    December 19, 2022, 6:01 AM 2022-12-19 06:01:00   \n",
       "3    December 19, 2022, 6:00 AM 2022-12-19 06:00:00   \n",
       "4    December 19, 2022, 6:00 AM 2022-12-19 06:00:00   \n",
       "..                          ...                 ...   \n",
       "688  December 19, 2022, 5:13 AM 2022-12-19 05:13:00   \n",
       "689  December 14, 2022, 5:10 AM 2022-12-14 05:10:00   \n",
       "690  December 12, 2022, 5:00 AM 2022-12-12 05:00:00   \n",
       "691   December 9, 2022, 5:00 PM 2022-12-09 17:00:00   \n",
       "692   December 8, 2022, 7:15 AM 2022-12-08 07:15:00   \n",
       "\n",
       "                                       related_tickers  \n",
       "0                                      [JNJ, MSFT, HD]  \n",
       "1                                    [CSCO, WIT, MSFT]  \n",
       "2                                     [TTC, LNN, MSFT]  \n",
       "3                                               [MSFT]  \n",
       "4                                               [AAPL]  \n",
       "..                                                 ...  \n",
       "688                                    [EOG, BKR, DVN]  \n",
       "689                                              [BKR]  \n",
       "690                                              [BKR]  \n",
       "691  [CSGP, WBD, BAIDF, BIDU, GFS, SWKS, FANG, ^NDX...  \n",
       "692                                              [BKR]  \n",
       "\n",
       "[693 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_df = pd.DataFrame(scrape_dict, columns=['scrape_date', 'index', 'url', 'news', 'headlines', 'raw_publish_date', 'publish_date', 'related_tickers'])\n",
    "scrape_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d28db2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../data/scraped_news_from_api'\n",
    "save_file = f'yahoo_finance_news_{date_today}.csv'\n",
    "scrape_df.to_csv(os.path.join(save_path, save_file), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35968b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
